{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TVAE module.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import Linear, Module, Parameter, ReLU, Sequential, GELU\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ctgan.data_transformer import DataTransformer\n",
    "from ctgan.synthesizers.base import BaseSynthesizer, random_state\n",
    "\n",
    "\n",
    "class Encoder(Module):\n",
    "    \"\"\"Encoder for the TVAE.\n",
    "\n",
    "    Args:\n",
    "        data_dim (int):\n",
    "            Dimensions of the data.\n",
    "        compress_dims (tuple or list of ints):\n",
    "            Size of each hidden layer.\n",
    "        embedding_dim (int):\n",
    "            Size of the output vector.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dim, compress_dims, embedding_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        dim = data_dim\n",
    "        seq = []\n",
    "        for item in list(compress_dims):\n",
    "            seq += [Linear(dim, item), GELU()]\n",
    "            dim = item\n",
    "\n",
    "        self.seq = Sequential(*seq)\n",
    "        self.fc1 = Linear(dim, embedding_dim)\n",
    "        self.fc2 = Linear(dim, embedding_dim)\n",
    "\n",
    "    def forward(self, input_):\n",
    "        \"\"\"Encode the passed `input_`.\"\"\"\n",
    "        feature = self.seq(input_)\n",
    "        mu = self.fc1(feature)\n",
    "        logvar = self.fc2(feature)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        return mu, std, logvar\n",
    "\n",
    "\n",
    "class Decoder(Module):\n",
    "    \"\"\"Decoder for the TVAE.\n",
    "\n",
    "    Args:\n",
    "        embedding_dim (int):\n",
    "            Size of the input vector.\n",
    "        decompress_dims (tuple or list of ints):\n",
    "            Size of each hidden layer.\n",
    "        data_dim (int):\n",
    "            Dimensions of the data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim, decompress_dims, data_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        dim = embedding_dim\n",
    "        seq = []\n",
    "        for item in list(decompress_dims):\n",
    "            seq += [Linear(dim, item), GELU()]\n",
    "            dim = item\n",
    "\n",
    "        seq.append(Linear(dim, data_dim))\n",
    "        self.seq = Sequential(*seq)\n",
    "        self.sigma = Parameter(torch.ones(data_dim) * 0.1)\n",
    "\n",
    "    def forward(self, input_):\n",
    "        \"\"\"Decode the passed `input_`.\"\"\"\n",
    "        return self.seq(input_), self.sigma\n",
    "\n",
    "\n",
    "def _loss_function(recon_x, x, sigmas, mu, logvar, output_info, factor):\n",
    "    st = 0\n",
    "    loss = []\n",
    "    for column_info in output_info:\n",
    "        for span_info in column_info:\n",
    "            if span_info.activation_fn != 'softmax':\n",
    "                ed = st + span_info.dim\n",
    "                std = sigmas[st]\n",
    "                eq = x[:, st] - torch.tanh(recon_x[:, st])\n",
    "                loss.append((eq**2 / 2 / (std**2)).sum())\n",
    "                loss.append(torch.log(std) * x.size()[0])\n",
    "                st = ed\n",
    "\n",
    "            else:\n",
    "                ed = st + span_info.dim\n",
    "                loss.append(\n",
    "                    cross_entropy(\n",
    "                        recon_x[:, st:ed], torch.argmax(x[:, st:ed], dim=-1), reduction='sum'\n",
    "                    )\n",
    "                )\n",
    "                st = ed\n",
    "\n",
    "    assert st == recon_x.size()[1]\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "    return sum(loss) * factor / x.size()[0], KLD / x.size()[0]\n",
    "\n",
    "\n",
    "class TVAE(BaseSynthesizer):\n",
    "    \"\"\"TVAE.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim=32,\n",
    "        compress_dims=(32, 1024),\n",
    "        decompress_dims=(1024, 32),\n",
    "        l2scale=1e-5,\n",
    "        batch_size=500,\n",
    "        epochs=300,\n",
    "        loss_factor=2,\n",
    "        cuda=False,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.compress_dims = compress_dims\n",
    "        self.decompress_dims = decompress_dims\n",
    "\n",
    "        self.l2scale = l2scale\n",
    "        self.batch_size = batch_size\n",
    "        self.loss_factor = loss_factor\n",
    "        self.epochs = epochs\n",
    "        self.loss_values = pd.DataFrame(columns=['Epoch', 'Batch', 'Loss'])\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if not cuda or not torch.cuda.is_available():\n",
    "            device = 'cpu'\n",
    "        elif isinstance(cuda, str):\n",
    "            device = cuda\n",
    "        else:\n",
    "            device = 'cuda'\n",
    "\n",
    "        self._device = torch.device(device)\n",
    "\n",
    "    @random_state\n",
    "    def fit(self, train_data, discrete_columns=()):\n",
    "        \"\"\"Fit the TVAE Synthesizer models to the training data.\n",
    "\n",
    "        Args:\n",
    "            train_data (numpy.ndarray or pandas.DataFrame):\n",
    "                Training Data. It must be a 2-dimensional numpy array or a pandas.DataFrame.\n",
    "            discrete_columns (list-like):\n",
    "                List of discrete columns to be used to generate the Conditional\n",
    "                Vector. If ``train_data`` is a Numpy array, this list should\n",
    "                contain the integer indices of the columns. Otherwise, if it is\n",
    "                a ``pandas.DataFrame``, this list should contain the column names.\n",
    "        \"\"\"\n",
    "        self.transformer = DataTransformer()\n",
    "        self.transformer.fit(train_data, discrete_columns)\n",
    "        train_data = self.transformer.transform(train_data)\n",
    "        dataset = TensorDataset(torch.from_numpy(train_data.astype('float32')).to(self._device))\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "        data_dim = self.transformer.output_dimensions\n",
    "        self.encoder = Encoder(data_dim, self.compress_dims, self.embedding_dim).to(self._device)\n",
    "        self.decoder = Decoder(self.embedding_dim, self.decompress_dims, data_dim).to(self._device)\n",
    "        optimizerAE = Adam(\n",
    "            list(self.encoder.parameters()) + list(self.decoder.parameters()), weight_decay=self.l2scale\n",
    "        )\n",
    "\n",
    "        self.loss_values = pd.DataFrame(columns=['Epoch', 'Batch', 'Loss'])\n",
    "        iterator = tqdm(range(self.epochs), disable=(not self.verbose))\n",
    "        if self.verbose:\n",
    "            iterator_description = 'Loss: {loss:.3f}'\n",
    "            iterator.set_description(iterator_description.format(loss=0))\n",
    "\n",
    "        for i in iterator:\n",
    "            loss_values = []\n",
    "            batch = []\n",
    "            for id_, data in enumerate(loader):\n",
    "                optimizerAE.zero_grad()\n",
    "                real = data[0].to(self._device)\n",
    "                mu, std, logvar = self.encoder(real)\n",
    "                eps = torch.randn_like(std)\n",
    "                emb = eps * std + mu\n",
    "                rec, sigmas = self.decoder(emb)\n",
    "                loss_1, loss_2 = _loss_function(\n",
    "                    rec,\n",
    "                    real,\n",
    "                    sigmas,\n",
    "                    mu,\n",
    "                    logvar,\n",
    "                    self.transformer.output_info_list,\n",
    "                    self.loss_factor,\n",
    "                )\n",
    "                loss = loss_1 + loss_2\n",
    "                loss.backward()\n",
    "                optimizerAE.step()\n",
    "                self.decoder.sigma.data.clamp_(0.01, 1.0)\n",
    "\n",
    "                batch.append(id_)\n",
    "                loss_values.append(loss.detach().cpu().item())\n",
    "\n",
    "            epoch_loss_df = pd.DataFrame({\n",
    "                'Epoch': [i] * len(batch),\n",
    "                'Batch': batch,\n",
    "                'Loss': loss_values,\n",
    "            })\n",
    "            if not self.loss_values.empty:\n",
    "                self.loss_values = pd.concat([self.loss_values, epoch_loss_df]).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "            else:\n",
    "                self.loss_values = epoch_loss_df\n",
    "\n",
    "            if self.verbose:\n",
    "                iterator.set_description(\n",
    "                    iterator_description.format(loss=loss.detach().cpu().item())\n",
    "                )\n",
    "\n",
    "    @random_state\n",
    "    def sample(self, samples, path=\"../data/external/bank.csv\"):\n",
    "        \"\"\"Sample data similar to the training data.\n",
    "\n",
    "        Args:\n",
    "            samples (int):\n",
    "                Number of rows to sample.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray or pandas.DataFrame\n",
    "        \"\"\"\n",
    "        self.decoder.eval()\n",
    "\n",
    "        steps = samples // self.batch_size + 1\n",
    "        data = []\n",
    "        for _ in range(steps):\n",
    "            embedding_data = pd.read_csv(path, sep=\",\")\n",
    "            fake, sigmas = self.decoder(torch.tensor(embedding_data.to_numpy(), dtype=torch.float32))\n",
    "            fake = torch.tanh(fake)\n",
    "            data.append(fake.detach().cpu().numpy())\n",
    "\n",
    "        data = np.concatenate(data, axis=0)\n",
    "        data = data[:samples]\n",
    "        return self.transformer.inverse_transform(data, sigmas.detach().cpu().numpy())\n",
    "\n",
    "    def generate_latents(self, data):\n",
    "        \"\"\"Generate latent vectors from the input data using the trained encoder.\n",
    "\n",
    "        Args:\n",
    "            data (numpy.ndarray or pandas.DataFrame):\n",
    "                Input data to encode. Must match the format used for training.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Latent vectors generated by the encoder.\n",
    "        \"\"\"\n",
    "        self.encoder.eval()\n",
    "        data = self.transformer.transform(data)\n",
    "        data_tensor = torch.from_numpy(data.astype('float32')).to(self._device)\n",
    "        \n",
    "        with torch.no_grad():  # Disable gradient calculations\n",
    "            mu, std, _ = self.encoder(data_tensor)  # Get mean and standard deviation from encoder\n",
    "            eps = torch.randn_like(std)  # Sample from a standard normal distribution\n",
    "            emb = eps * std + mu  # Reparameterization trick to sample from the latent space\n",
    "\n",
    "        return emb.cpu().numpy() \n",
    "    \n",
    "    def set_device(self, device):\n",
    "        \"\"\"Set the `device` to be used ('GPU' or 'CPU).\"\"\"\n",
    "        self._device = device\n",
    "        self.decoder.to(self._device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_column_indices(metadata_dict):\n",
    "    categorical_indices = []\n",
    "    columns = metadata_dict.get('columns', {})\n",
    "    column_names = list(columns.keys())[:-1]  # Exclude the last key\n",
    "    for index, column_name in enumerate(column_names):\n",
    "        column_data = columns[column_name]\n",
    "        if column_data.get('sdtype') == 'categorical':\n",
    "            categorical_indices.append(index)\n",
    "    return categorical_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_latent(model, source=\"../data/interim/bank_no_label.csv\", path=\"../data/processed/bank,.csv\"):\n",
    "    DATA_PATH = source\n",
    "    df = pd.read_csv(DATA_PATH, sep=\",\")\n",
    "    actual_data = df #.iloc[:, :-1]\n",
    "    # outcomes = df.iloc[:, -1]\n",
    "\n",
    "    latents = []\n",
    "    metadata = SingleTableMetadata()\n",
    "    meta = metadata.detect_from_csv(source)\n",
    "\n",
    "    discrete_columns = categorical_column_indices(metadata.to_dict())\n",
    "    print(discrete_columns)\n",
    "    model.fit(actual_data, discrete_columns)\n",
    "    latents = model.generate_latents(actual_data)\n",
    "    # unbatched_latent = torch.cat(latents, dim=0)\n",
    "\n",
    "    latents_df = pd.DataFrame(latents) #(unbatched_latent)\n",
    "    # outcomes_df = pd.DataFrame(outcomes)\n",
    "    # Save DataFrame to a CSV file\n",
    "    # data_with_outcomes = pd.concat([latents_df, outcomes_df], axis=1)\n",
    "\n",
    "    # data_with_outcomes.to_csv(path, index=False)\n",
    "    latents_df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_columns(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Split the input DataFrame into two parts:\n",
    "    - all columns except the last one\n",
    "    - the last column\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.Series: A DataFrame with all columns except the last one, and the last column as a Series.\n",
    "    \"\"\"\n",
    "    # All columns except the last one\n",
    "    all_except_last = df.iloc[:, :-1]\n",
    "\n",
    "    # The last column\n",
    "    last_column = df.iloc[:, -1]\n",
    "    all_except_last.to_csv(\"../data/interim/bank_no_label.csv\", index=False)\n",
    "    return all_except_last, last_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7, 9, 10, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -42.321: 100%|██████████| 300/300 [12:15<00:00,  2.45s/it]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/raw/bank.csv\", sep=\",\")\n",
    "_, label = split_columns(data)\n",
    "no_label_data = pd.read_csv(\"../data/interim/bank_no_label.csv\", sep=\",\")\n",
    "model = TVAE(embedding_dim=no_label_data.shape[1], compress_dims=(32,1024), decompress_dims=(1024,32))\n",
    "generate_and_save_latent(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_check = pd.read_csv(\"../data/processed/bank,.csv\")\n",
    "combined_df = pd.concat([latent_check, label], axis=1)\n",
    "combined_df.to_csv(\"../data/processed/bank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data = np.load(\"../central_backbone/exp/bank_latent/X_num_unnorm.npy\")\n",
    "df = pd.DataFrame(gen_data)\n",
    "df.to_csv(\"../data/external/bank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>524</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>94858</td>\n",
       "      <td>2</td>\n",
       "      <td>4.229875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>683</td>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>94935</td>\n",
       "      <td>1</td>\n",
       "      <td>1.781621</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4320</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>94817</td>\n",
       "      <td>4</td>\n",
       "      <td>0.324909</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>447</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>95161</td>\n",
       "      <td>1</td>\n",
       "      <td>2.166897</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>623</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>95147</td>\n",
       "      <td>4</td>\n",
       "      <td>0.224853</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4729</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>94742</td>\n",
       "      <td>4</td>\n",
       "      <td>0.543778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4492</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>94437</td>\n",
       "      <td>1</td>\n",
       "      <td>1.079280</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4309</td>\n",
       "      <td>63</td>\n",
       "      <td>35</td>\n",
       "      <td>67</td>\n",
       "      <td>95060</td>\n",
       "      <td>1</td>\n",
       "      <td>1.053149</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>3326</td>\n",
       "      <td>66</td>\n",
       "      <td>40</td>\n",
       "      <td>14</td>\n",
       "      <td>94563</td>\n",
       "      <td>2</td>\n",
       "      <td>2.374530</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4714</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>94310</td>\n",
       "      <td>2</td>\n",
       "      <td>1.952456</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Age  Experience  Income  ZIP Code  Family     CCAvg  Education  \\\n",
       "0      524   25           1     121     94858       2  4.229875          1   \n",
       "1      683   44          18      23     94935       1  1.781621          1   \n",
       "2     4320   33           6      31     94817       4  0.324909          2   \n",
       "3      447   27           4      83     95161       1  2.166897          1   \n",
       "4      623   32          13      33     95147       4  0.224853          3   \n",
       "...    ...  ...         ...     ...       ...     ...       ...        ...   \n",
       "4995  4729   29           3      69     94742       4  0.543778          1   \n",
       "4996  4492   31           4      46     94437       1  1.079280          1   \n",
       "4997  4309   63          35      67     95060       1  1.053149          3   \n",
       "4998  3326   66          40      14     94563       2  2.374530          3   \n",
       "4999  4714   29           4     101     94310       2  1.952456          1   \n",
       "\n",
       "      Mortgage  Personal Loan  Securities Account  CD Account  Online  \n",
       "0            0              0                   0           0       1  \n",
       "1            1              0                   0           0       1  \n",
       "2            1              0                   0           0       1  \n",
       "3            1              0                   0           0       1  \n",
       "4            0              0                   0           0       1  \n",
       "...        ...            ...                 ...         ...     ...  \n",
       "4995         0              0                   0           0       1  \n",
       "4996        -1              0                   0           0       1  \n",
       "4997         1              0                   0           0       1  \n",
       "4998         0              0                   0           0       1  \n",
       "4999         0              0                   0           0       1  \n",
       "\n",
       "[5000 rows x 13 columns]"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_df = model.sample(5000)\n",
    "gen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4996</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>92697</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4997</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>92037</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4998</td>\n",
       "      <td>63</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>93023</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4999</td>\n",
       "      <td>65</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>90034</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>5000</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>92612</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  \\\n",
       "0        1   25           1      49     91107       4    1.6          1   \n",
       "1        2   45          19      34     90089       3    1.5          1   \n",
       "2        3   39          15      11     94720       1    1.0          1   \n",
       "3        4   35           9     100     94112       1    2.7          2   \n",
       "4        5   35           8      45     91330       4    1.0          2   \n",
       "...    ...  ...         ...     ...       ...     ...    ...        ...   \n",
       "4995  4996   29           3      40     92697       1    1.9          3   \n",
       "4996  4997   30           4      15     92037       4    0.4          1   \n",
       "4997  4998   63          39      24     93023       2    0.3          3   \n",
       "4998  4999   65          40      49     90034       3    0.5          2   \n",
       "4999  5000   28           4      83     92612       3    0.8          1   \n",
       "\n",
       "      Mortgage  Personal Loan  Securities Account  CD Account  Online  \n",
       "0            0              0                   1           0       0  \n",
       "1            0              0                   1           0       0  \n",
       "2            0              0                   0           0       0  \n",
       "3            0              0                   0           0       0  \n",
       "4            0              0                   0           0       0  \n",
       "...        ...            ...                 ...         ...     ...  \n",
       "4995         0              0                   0           0       1  \n",
       "4996        85              0                   0           0       1  \n",
       "4997         0              0                   0           0       0  \n",
       "4998         0              0                   0           0       1  \n",
       "4999         0              0                   0           0       1  \n",
       "\n",
       "[5000 rows x 13 columns]"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_df = pd.read_csv(\"../data/raw/bank.csv\", sep=\",\")\n",
    "real_df = real_df.iloc[:, :-1]\n",
    "real_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resemblance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, ks_2samp\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_categorical_similarity(col_real, col_synthetic):\n",
    "    # Compute Theil's U for categorical features\n",
    "    p_real = pd.Series(col_real).value_counts(normalize=True)\n",
    "    p_synthetic = pd.Series(col_synthetic).value_counts(normalize=True)\n",
    "    u = (p_real * np.log(p_real / p_synthetic)).sum()\n",
    "    return 1 - u\n",
    "def column_similarity(real_data, synthetic_data):\n",
    "    similarities = []\n",
    "    for col_real, col_synthetic in zip(real_data, synthetic_data):\n",
    "        correlation, _ = pearsonr(col_real, col_synthetic)\n",
    "        similarity = correlation\n",
    "        similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "def correlation_similarity(real_data, synthetic_data):\n",
    "    real_corr = np.corrcoef(real_data, rowvar=False)\n",
    "    synthetic_corr = np.corrcoef(synthetic_data, rowvar=False)\n",
    "    print(synthetic_corr)\n",
    "    correlation, _ = pearsonr(real_corr.flatten(), synthetic_corr.flatten())\n",
    "    return correlation\n",
    "def jensen_shannon_similarity(real_data, synthetic_data):\n",
    "    similarities = []\n",
    "    for col_real, col_synthetic in zip(real_data.T, synthetic_data.T):\n",
    "        # Compute probability distributions and Jensen-Shannon divergence\n",
    "        p_real = np.histogram(col_real, bins=10, density=True)[0]\n",
    "        p_synthetic = np.histogram(col_synthetic, bins=10, density=True)[0]\n",
    "        similarity = 1 - jensenshannon(p_real, p_synthetic)\n",
    "        similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "def kolmogorov_smirnov_similarity(real_data, synthetic_data):\n",
    "    similarities = []\n",
    "    for col_real, col_synthetic in zip(real_data.T, synthetic_data.T):\n",
    "        # Compute cumulative distributions and Kolmogorov-Smirnov distance\n",
    "        similarity, _ = ks_2samp(col_real, col_synthetic)\n",
    "        similarity = 1 - similarity\n",
    "        similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "def propensity_mean_absolute_similarity(real_data, synthetic_data):\n",
    "    # Train XGBoost classifier to discriminate between real and synthetic samples\n",
    "    X = np.vstack([real_data, synthetic_data])\n",
    "    y = np.concatenate([np.ones(len(real_data)), np.zeros(len(synthetic_data))])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    classifier = XGBClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # Compute mean absolute error of classifier probabilities\n",
    "    y_pred_proba = classifier.predict_proba(X_test)[:, 1]\n",
    "    error = mean_absolute_error(y_test, y_pred_proba)\n",
    "    return 1 - error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resemblance_measure(real_data, synthetic_data):\n",
    "    resemblance_score = (\n",
    "        column_similarity(real_data, synthetic_data) +\n",
    "        # correlation_similarity(real_data, synthetic_data) +\n",
    "        jensen_shannon_similarity(real_data, synthetic_data) +\n",
    "        kolmogorov_smirnov_similarity(real_data, synthetic_data) +\n",
    "        propensity_mean_absolute_similarity(real_data, synthetic_data)\n",
    "    ) / 4\n",
    "    print(\"Resemblance Score:\", resemblance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resemblance Score: 0.8636330978384504\n"
     ]
    }
   ],
   "source": [
    "resemblance_measure(real_df.to_numpy(), gen_df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -8.47259459e-03 -8.32575989e-03 -1.76947432e-02\n",
      "   1.34315402e-02 -1.67972432e-02 -2.46751718e-02  2.14632093e-02\n",
      "  -1.39199177e-02 -2.48011655e-02 -1.69723327e-02 -6.90940312e-03\n",
      "  -2.52841007e-03  1.70282321e-02]\n",
      " [-8.47259459e-03  1.00000000e+00  9.94214857e-01 -5.52686182e-02\n",
      "  -2.92162874e-02 -4.64176636e-02 -5.20121791e-02  4.13343834e-02\n",
      "  -1.25385869e-02 -7.72561717e-03 -4.36242223e-04  8.04255215e-03\n",
      "   1.37024021e-02  7.68103676e-03]\n",
      " [-8.32575989e-03  9.94214857e-01  1.00000000e+00 -4.65741777e-02\n",
      "  -2.86255480e-02 -5.25631471e-02 -5.00765106e-02  1.31518129e-02\n",
      "  -1.05815524e-02 -7.41309808e-03 -1.23213441e-03  1.03533312e-02\n",
      "   1.38978996e-02  8.96744734e-03]\n",
      " [-1.76947432e-02 -5.52686182e-02 -4.65741777e-02  1.00000000e+00\n",
      "  -1.64098117e-02 -1.57500785e-01  6.45983670e-01 -1.87524257e-01\n",
      "   2.06806228e-01  5.02462292e-01 -2.61649670e-03  1.69738080e-01\n",
      "   1.42059193e-02 -2.38500775e-03]\n",
      " [ 1.34315402e-02 -2.92162874e-02 -2.86255480e-02 -1.64098117e-02\n",
      "   1.00000000e+00  1.17782049e-02 -4.06068490e-03 -1.73767564e-02\n",
      "   7.38337775e-03  1.07376354e-04  4.70423961e-03  1.99719123e-02\n",
      "   1.69900666e-02  7.69139484e-03]\n",
      " [-1.67972432e-02 -4.64176636e-02 -5.25631471e-02 -1.57500785e-01\n",
      "   1.17782049e-02  1.00000000e+00 -1.09274506e-01  6.49289136e-02\n",
      "  -2.04449310e-02  6.13670440e-02  1.99940798e-02  1.41103648e-02\n",
      "   1.03540362e-02  1.15880661e-02]\n",
      " [-2.46751718e-02 -5.20121791e-02 -5.00765106e-02  6.45983670e-01\n",
      "  -4.06068490e-03 -1.09274506e-01  1.00000000e+00 -1.36123922e-01\n",
      "   1.09904723e-01  3.66888736e-01  1.50863114e-02  1.36533655e-01\n",
      "  -3.61100946e-03 -6.68949441e-03]\n",
      " [ 2.14632093e-02  4.13343834e-02  1.31518129e-02 -1.87524257e-01\n",
      "  -1.73767564e-02  6.49289136e-02 -1.36123922e-01  1.00000000e+00\n",
      "  -3.33271246e-02  1.36721550e-01 -1.08120136e-02  1.39338882e-02\n",
      "  -1.50038206e-02 -1.10141340e-02]\n",
      " [-1.39199177e-02 -1.25385869e-02 -1.05815524e-02  2.06806228e-01\n",
      "   7.38337775e-03 -2.04449310e-02  1.09904723e-01 -3.33271246e-02\n",
      "   1.00000000e+00  1.42095236e-01 -5.41097005e-03  8.93110582e-02\n",
      "  -5.99489836e-03 -7.23091943e-03]\n",
      " [-2.48011655e-02 -7.72561717e-03 -7.41309808e-03  5.02462292e-01\n",
      "   1.07376354e-04  6.13670440e-02  3.66888736e-01  1.36721550e-01\n",
      "   1.42095236e-01  1.00000000e+00  2.19538822e-02  3.16354829e-01\n",
      "   6.27781540e-03  2.80150884e-03]\n",
      " [-1.69723327e-02 -4.36242223e-04 -1.23213441e-03 -2.61649670e-03\n",
      "   4.70423961e-03  1.99940798e-02  1.50863114e-02 -1.08120136e-02\n",
      "  -5.41097005e-03  2.19538822e-02  1.00000000e+00  3.17034416e-01\n",
      "   1.26274704e-02 -1.50283189e-02]\n",
      " [-6.90940312e-03  8.04255215e-03  1.03533312e-02  1.69738080e-01\n",
      "   1.99719123e-02  1.41103648e-02  1.36533655e-01  1.39338882e-02\n",
      "   8.93110582e-02  3.16354829e-01  3.17034416e-01  1.00000000e+00\n",
      "   1.75880016e-01  2.78644365e-01]\n",
      " [-2.52841007e-03  1.37024021e-02  1.38978996e-02  1.42059193e-02\n",
      "   1.69900666e-02  1.03540362e-02 -3.61100946e-03 -1.50038206e-02\n",
      "  -5.99489836e-03  6.27781540e-03  1.26274704e-02  1.75880016e-01\n",
      "   1.00000000e+00  4.20965615e-03]\n",
      " [ 1.70282321e-02  7.68103676e-03  8.96744734e-03 -2.38500775e-03\n",
      "   7.69139484e-03  1.15880661e-02 -6.68949441e-03 -1.10141340e-02\n",
      "  -7.23091943e-03  2.80150884e-03 -1.50283189e-02  2.78644365e-01\n",
      "   4.20965615e-03  1.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnobchowdhury/anaconda3/envs/distributed-3-9/lib/python3.9/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/arnobchowdhury/anaconda3/envs/distributed-3-9/lib/python3.9/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[417], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m correlation_similarity(real_df\u001b[39m.\u001b[39;49mto_numpy(), gen_df\u001b[39m.\u001b[39;49mto_numpy())\n",
      "Cell \u001b[0;32mIn[416], line 18\u001b[0m, in \u001b[0;36mcorrelation_similarity\u001b[0;34m(real_data, synthetic_data)\u001b[0m\n\u001b[1;32m     16\u001b[0m synthetic_corr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcorrcoef(synthetic_data, rowvar\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(real_corr)\n\u001b[0;32m---> 18\u001b[0m correlation, _ \u001b[39m=\u001b[39m pearsonr(real_corr\u001b[39m.\u001b[39;49mflatten(), synthetic_corr\u001b[39m.\u001b[39;49mflatten())\n\u001b[1;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m correlation\n",
      "File \u001b[0;32m~/anaconda3/envs/distributed-3-9/lib/python3.9/site-packages/scipy/stats/_stats_py.py:4838\u001b[0m, in \u001b[0;36mpearsonr\u001b[0;34m(x, y, alternative, method)\u001b[0m\n\u001b[1;32m   4834\u001b[0m \u001b[39m# Unlike np.linalg.norm or the expression sqrt((xm*xm).sum()),\u001b[39;00m\n\u001b[1;32m   4835\u001b[0m \u001b[39m# scipy.linalg.norm(xm) does not overflow if xm is, for example,\u001b[39;00m\n\u001b[1;32m   4836\u001b[0m \u001b[39m# [-5e210, 5e210, 3e200, -3e200]\u001b[39;00m\n\u001b[1;32m   4837\u001b[0m normxm \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mnorm(xm)\n\u001b[0;32m-> 4838\u001b[0m normym \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49mnorm(ym)\n\u001b[1;32m   4840\u001b[0m threshold \u001b[39m=\u001b[39m \u001b[39m1e-13\u001b[39m\n\u001b[1;32m   4841\u001b[0m \u001b[39mif\u001b[39;00m normxm \u001b[39m<\u001b[39m threshold\u001b[39m*\u001b[39m\u001b[39mabs\u001b[39m(xmean) \u001b[39mor\u001b[39;00m normym \u001b[39m<\u001b[39m threshold\u001b[39m*\u001b[39m\u001b[39mabs\u001b[39m(ymean):\n\u001b[1;32m   4842\u001b[0m     \u001b[39m# If all the values in x (likewise y) are very close to the mean,\u001b[39;00m\n\u001b[1;32m   4843\u001b[0m     \u001b[39m# the loss of precision that occurs in the subtraction xm = x - xmean\u001b[39;00m\n\u001b[1;32m   4844\u001b[0m     \u001b[39m# might result in large errors in r.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/distributed-3-9/lib/python3.9/site-packages/scipy/linalg/_misc.py:146\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(a, ord, axis, keepdims, check_finite)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m# Differs from numpy only in non-finite handling and the use of blas.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m check_finite:\n\u001b[0;32m--> 146\u001b[0m     a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray_chkfinite(a)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(a)\n",
      "File \u001b[0;32m~/anaconda3/envs/distributed-3-9/lib/python3.9/site-packages/numpy/lib/function_base.py:630\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    628\u001b[0m a \u001b[39m=\u001b[39m asarray(a, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder)\n\u001b[1;32m    629\u001b[0m \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mchar \u001b[39min\u001b[39;00m typecodes[\u001b[39m'\u001b[39m\u001b[39mAllFloat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(a)\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 630\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    631\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marray must not contain infs or NaNs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    632\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "correlation_similarity(real_df.to_numpy(), gen_df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 13)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_check = pd.read_csv(\"../data/processed/bank,.csv\")\n",
    "latent_check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 ('distributed-3-9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71c2bb8a9aafac3189ddd139a8a38ed74f79c7c3756567015645529460b394b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
