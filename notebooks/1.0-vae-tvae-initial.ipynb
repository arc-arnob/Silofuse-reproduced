{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TVAE module.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import Linear, Module, Parameter, ReLU, Sequential, GELU\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ctgan.data_transformer import DataTransformer\n",
    "from ctgan.synthesizers.base import BaseSynthesizer, random_state\n",
    "\n",
    "\n",
    "class Encoder(Module):\n",
    "    \"\"\"Encoder for the TVAE.\n",
    "\n",
    "    Args:\n",
    "        data_dim (int):\n",
    "            Dimensions of the data.\n",
    "        compress_dims (tuple or list of ints):\n",
    "            Size of each hidden layer.\n",
    "        embedding_dim (int):\n",
    "            Size of the output vector.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dim, compress_dims, embedding_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        dim = data_dim\n",
    "        seq = []\n",
    "        for item in list(compress_dims):\n",
    "            seq += [Linear(dim, item), GELU()]\n",
    "            dim = item\n",
    "\n",
    "        self.seq = Sequential(*seq)\n",
    "        self.fc1 = Linear(dim, embedding_dim)\n",
    "        self.fc2 = Linear(dim, embedding_dim)\n",
    "\n",
    "    def forward(self, input_):\n",
    "        \"\"\"Encode the passed `input_`.\"\"\"\n",
    "        feature = self.seq(input_)\n",
    "        mu = self.fc1(feature)\n",
    "        logvar = self.fc2(feature)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        return mu, std, logvar\n",
    "\n",
    "\n",
    "class Decoder(Module):\n",
    "    \"\"\"Decoder for the TVAE.\n",
    "\n",
    "    Args:\n",
    "        embedding_dim (int):\n",
    "            Size of the input vector.\n",
    "        decompress_dims (tuple or list of ints):\n",
    "            Size of each hidden layer.\n",
    "        data_dim (int):\n",
    "            Dimensions of the data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim, decompress_dims, data_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        dim = embedding_dim\n",
    "        seq = []\n",
    "        for item in list(decompress_dims):\n",
    "            seq += [Linear(dim, item), GELU()]\n",
    "            dim = item\n",
    "\n",
    "        seq.append(Linear(dim, data_dim))\n",
    "        self.seq = Sequential(*seq)\n",
    "        self.sigma = Parameter(torch.ones(data_dim) * 0.1)\n",
    "\n",
    "    def forward(self, input_):\n",
    "        \"\"\"Decode the passed `input_`.\"\"\"\n",
    "        return self.seq(input_), self.sigma\n",
    "\n",
    "\n",
    "def _loss_function(recon_x, x, sigmas, mu, logvar, output_info, factor):\n",
    "    st = 0\n",
    "    loss = []\n",
    "    for column_info in output_info:\n",
    "        for span_info in column_info:\n",
    "            if span_info.activation_fn != 'softmax':\n",
    "                ed = st + span_info.dim\n",
    "                std = sigmas[st]\n",
    "                eq = x[:, st] - torch.tanh(recon_x[:, st])\n",
    "                loss.append((eq**2 / 2 / (std**2)).sum())\n",
    "                loss.append(torch.log(std) * x.size()[0])\n",
    "                st = ed\n",
    "\n",
    "            else:\n",
    "                ed = st + span_info.dim\n",
    "                loss.append(\n",
    "                    cross_entropy(\n",
    "                        recon_x[:, st:ed], torch.argmax(x[:, st:ed], dim=-1), reduction='sum'\n",
    "                    )\n",
    "                )\n",
    "                st = ed\n",
    "\n",
    "    assert st == recon_x.size()[1]\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "    return sum(loss) * factor / x.size()[0], KLD / x.size()[0]\n",
    "\n",
    "\n",
    "class TVAE(BaseSynthesizer):\n",
    "    \"\"\"TVAE.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim=32,\n",
    "        compress_dims=(32, 1024),\n",
    "        decompress_dims=(1024, 32),\n",
    "        l2scale=1e-5,\n",
    "        batch_size=500,\n",
    "        epochs=300,\n",
    "        loss_factor=2,\n",
    "        cuda=False,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.compress_dims = compress_dims\n",
    "        self.decompress_dims = decompress_dims\n",
    "\n",
    "        self.l2scale = l2scale\n",
    "        self.batch_size = batch_size\n",
    "        self.loss_factor = loss_factor\n",
    "        self.epochs = epochs\n",
    "        self.loss_values = pd.DataFrame(columns=['Epoch', 'Batch', 'Loss'])\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if not cuda or not torch.cuda.is_available():\n",
    "            device = 'cpu'\n",
    "        elif isinstance(cuda, str):\n",
    "            device = cuda\n",
    "        else:\n",
    "            device = 'cuda'\n",
    "\n",
    "        self._device = torch.device(device)\n",
    "\n",
    "    @random_state\n",
    "    def fit(self, train_data, discrete_columns=()):\n",
    "        \"\"\"Fit the TVAE Synthesizer models to the training data.\n",
    "\n",
    "        Args:\n",
    "            train_data (numpy.ndarray or pandas.DataFrame):\n",
    "                Training Data. It must be a 2-dimensional numpy array or a pandas.DataFrame.\n",
    "            discrete_columns (list-like):\n",
    "                List of discrete columns to be used to generate the Conditional\n",
    "                Vector. If ``train_data`` is a Numpy array, this list should\n",
    "                contain the integer indices of the columns. Otherwise, if it is\n",
    "                a ``pandas.DataFrame``, this list should contain the column names.\n",
    "        \"\"\"\n",
    "        self.transformer = DataTransformer()\n",
    "        self.transformer.fit(train_data, discrete_columns)\n",
    "        train_data = self.transformer.transform(train_data)\n",
    "        dataset = TensorDataset(torch.from_numpy(train_data.astype('float32')).to(self._device))\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "        data_dim = self.transformer.output_dimensions\n",
    "        self.encoder = Encoder(data_dim, self.compress_dims, self.embedding_dim).to(self._device)\n",
    "        self.decoder = Decoder(self.embedding_dim, self.decompress_dims, data_dim).to(self._device)\n",
    "        optimizerAE = Adam(\n",
    "            list(self.encoder.parameters()) + list(self.decoder.parameters()), weight_decay=self.l2scale\n",
    "        )\n",
    "\n",
    "        self.loss_values = pd.DataFrame(columns=['Epoch', 'Batch', 'Loss'])\n",
    "        iterator = tqdm(range(self.epochs), disable=(not self.verbose))\n",
    "        if self.verbose:\n",
    "            iterator_description = 'Loss: {loss:.3f}'\n",
    "            iterator.set_description(iterator_description.format(loss=0))\n",
    "\n",
    "        for i in iterator:\n",
    "            loss_values = []\n",
    "            batch = []\n",
    "            for id_, data in enumerate(loader):\n",
    "                optimizerAE.zero_grad()\n",
    "                real = data[0].to(self._device)\n",
    "                mu, std, logvar = self.encoder(real)\n",
    "                eps = torch.randn_like(std)\n",
    "                emb = eps * std + mu\n",
    "                rec, sigmas = self.decoder(emb)\n",
    "                loss_1, loss_2 = _loss_function(\n",
    "                    rec,\n",
    "                    real,\n",
    "                    sigmas,\n",
    "                    mu,\n",
    "                    logvar,\n",
    "                    self.transformer.output_info_list,\n",
    "                    self.loss_factor,\n",
    "                )\n",
    "                loss = loss_1 + loss_2\n",
    "                loss.backward()\n",
    "                optimizerAE.step()\n",
    "                self.decoder.sigma.data.clamp_(0.01, 1.0)\n",
    "\n",
    "                batch.append(id_)\n",
    "                loss_values.append(loss.detach().cpu().item())\n",
    "\n",
    "            epoch_loss_df = pd.DataFrame({\n",
    "                'Epoch': [i] * len(batch),\n",
    "                'Batch': batch,\n",
    "                'Loss': loss_values,\n",
    "            })\n",
    "            if not self.loss_values.empty:\n",
    "                self.loss_values = pd.concat([self.loss_values, epoch_loss_df]).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "            else:\n",
    "                self.loss_values = epoch_loss_df\n",
    "\n",
    "            if self.verbose:\n",
    "                iterator.set_description(\n",
    "                    iterator_description.format(loss=loss.detach().cpu().item())\n",
    "                )\n",
    "\n",
    "    @random_state\n",
    "    def sample(self, samples, path=\"../data/processed/bank,.csv\"):\n",
    "        \"\"\"Sample data similar to the training data.\n",
    "\n",
    "        Args:\n",
    "            samples (int):\n",
    "                Number of rows to sample.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray or pandas.DataFrame\n",
    "        \"\"\"\n",
    "        self.decoder.eval()\n",
    "\n",
    "        steps = samples // self.batch_size + 1\n",
    "        data = []\n",
    "        for _ in range(steps):\n",
    "            embedding_data = pd.read_csv(path, sep=\",\")\n",
    "            fake, sigmas = self.decoder(torch.tensor(embedding_data.to_numpy(), dtype=torch.float32))\n",
    "            fake = torch.tanh(fake)\n",
    "            data.append(fake.detach().cpu().numpy())\n",
    "\n",
    "        data = np.concatenate(data, axis=0)\n",
    "        data = data[:samples]\n",
    "        return self.transformer.inverse_transform(data, sigmas.detach().cpu().numpy())\n",
    "\n",
    "    def generate_latents(self, data):\n",
    "        \"\"\"Generate latent vectors from the input data using the trained encoder.\n",
    "\n",
    "        Args:\n",
    "            data (numpy.ndarray or pandas.DataFrame):\n",
    "                Input data to encode. Must match the format used for training.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Latent vectors generated by the encoder.\n",
    "        \"\"\"\n",
    "        self.encoder.eval()\n",
    "        data = self.transformer.transform(data)\n",
    "        data_tensor = torch.from_numpy(data.astype('float32')).to(self._device)\n",
    "        \n",
    "        with torch.no_grad():  # Disable gradient calculations\n",
    "            mu, std, _ = self.encoder(data_tensor)  # Get mean and standard deviation from encoder\n",
    "            eps = torch.randn_like(std)  # Sample from a standard normal distribution\n",
    "            emb = eps * std + mu  # Reparameterization trick to sample from the latent space\n",
    "\n",
    "        return emb.cpu().numpy() \n",
    "    \n",
    "    def set_device(self, device):\n",
    "        \"\"\"Set the `device` to be used ('GPU' or 'CPU).\"\"\"\n",
    "        self._device = device\n",
    "        self.decoder.to(self._device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_column_indices(metadata_dict):\n",
    "    categorical_indices = []\n",
    "    columns = metadata_dict.get('columns', {})\n",
    "    column_names = list(columns.keys())[:-1]  # Exclude the last key\n",
    "    for index, column_name in enumerate(column_names):\n",
    "        column_data = columns[column_name]\n",
    "        if column_data.get('sdtype') == 'categorical':\n",
    "            categorical_indices.append(index)\n",
    "    return categorical_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_latent(model, source=\"../data/raw/bank.csv\", path=\"../data/processed/bank,.csv\"):\n",
    "    DATA_PATH = source\n",
    "    df = pd.read_csv(DATA_PATH, sep=\",\")\n",
    "    actual_data = df #.iloc[:, :-1]\n",
    "    # outcomes = df.iloc[:, -1]\n",
    "\n",
    "    latents = []\n",
    "    metadata = SingleTableMetadata()\n",
    "    meta = metadata.detect_from_csv(source)\n",
    "\n",
    "    discrete_columns = categorical_column_indices(metadata.to_dict())\n",
    "    print(discrete_columns)\n",
    "    model.fit(actual_data, discrete_columns)\n",
    "    latents = model.generate_latents(actual_data)\n",
    "    # unbatched_latent = torch.cat(latents, dim=0)\n",
    "\n",
    "    latents_df = pd.DataFrame(latents) #(unbatched_latent)\n",
    "    # outcomes_df = pd.DataFrame(outcomes)\n",
    "    # Save DataFrame to a CSV file\n",
    "    # data_with_outcomes = pd.concat([latents_df, outcomes_df], axis=1)\n",
    "\n",
    "    # data_with_outcomes.to_csv(path, index=False)\n",
    "    latents_df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7, 9, 10, 11, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -39.951: 100%|██████████| 30/30 [01:12<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/raw/bank.csv\", sep=\",\")\n",
    "model = TVAE(embedding_dim=data.shape[1], compress_dims=(32,1024), decompress_dims=(1024,32))\n",
    "generate_and_save_latent(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>746</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>94489</td>\n",
       "      <td>1</td>\n",
       "      <td>1.385850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>629</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>94834</td>\n",
       "      <td>1</td>\n",
       "      <td>1.537091</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>94790</td>\n",
       "      <td>1</td>\n",
       "      <td>1.367865</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>94541</td>\n",
       "      <td>1</td>\n",
       "      <td>1.295946</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>94338</td>\n",
       "      <td>1</td>\n",
       "      <td>1.947235</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>355</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>94653</td>\n",
       "      <td>2</td>\n",
       "      <td>2.106720</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>371</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>31</td>\n",
       "      <td>94637</td>\n",
       "      <td>1</td>\n",
       "      <td>1.726596</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>629</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>94569</td>\n",
       "      <td>1</td>\n",
       "      <td>2.132657</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>218</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>94826</td>\n",
       "      <td>1</td>\n",
       "      <td>1.046014</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>503</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>94612</td>\n",
       "      <td>1</td>\n",
       "      <td>1.917150</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Age  Experience  Income  ZIP Code  Family     CCAvg  Education  \\\n",
       "0     746   59          10      14     94489       1  1.385850          1   \n",
       "1     629   63           8      38     94834       1  1.537091          1   \n",
       "2     217   65           2      30     94790       1  1.367865          1   \n",
       "3     192   26           3      44     94541       1  1.295946          1   \n",
       "4      37   29           1      50     94338       1  1.947235          1   \n",
       "...   ...  ...         ...     ...       ...     ...       ...        ...   \n",
       "4995  355   29           1      44     94653       2  2.106720          1   \n",
       "4996  371   26          -1      31     94637       1  1.726596          1   \n",
       "4997  629   66           7      33     94569       1  2.132657          1   \n",
       "4998  218   61           2      36     94826       1  1.046014          1   \n",
       "4999  503   62           4      52     94612       1  1.917150          1   \n",
       "\n",
       "      Mortgage  Personal Loan  Securities Account  CD Account  Online  \\\n",
       "0            1              0                   0           0       1   \n",
       "1           -1              0                   0           0       1   \n",
       "2            0              0                   0           0       1   \n",
       "3            2              0                   0           0       1   \n",
       "4            0              0                   0           0       1   \n",
       "...        ...            ...                 ...         ...     ...   \n",
       "4995        -2              0                   0           0       1   \n",
       "4996         2              0                   0           0       1   \n",
       "4997         0              0                   0           0       1   \n",
       "4998        -1              0                   0           0       1   \n",
       "4999         2              0                   0           0       1   \n",
       "\n",
       "      CreditCard  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "4995           0  \n",
       "4996           0  \n",
       "4997           0  \n",
       "4998           0  \n",
       "4999           0  \n",
       "\n",
       "[5000 rows x 14 columns]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_df = model.sample(5000)\n",
    "gen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4996</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>92697</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4997</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>92037</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4998</td>\n",
       "      <td>63</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>93023</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4999</td>\n",
       "      <td>65</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>90034</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>5000</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>92612</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  \\\n",
       "0        1   25           1      49     91107       4    1.6          1   \n",
       "1        2   45          19      34     90089       3    1.5          1   \n",
       "2        3   39          15      11     94720       1    1.0          1   \n",
       "3        4   35           9     100     94112       1    2.7          2   \n",
       "4        5   35           8      45     91330       4    1.0          2   \n",
       "...    ...  ...         ...     ...       ...     ...    ...        ...   \n",
       "4995  4996   29           3      40     92697       1    1.9          3   \n",
       "4996  4997   30           4      15     92037       4    0.4          1   \n",
       "4997  4998   63          39      24     93023       2    0.3          3   \n",
       "4998  4999   65          40      49     90034       3    0.5          2   \n",
       "4999  5000   28           4      83     92612       3    0.8          1   \n",
       "\n",
       "      Mortgage  Personal Loan  Securities Account  CD Account  Online  \\\n",
       "0            0              0                   1           0       0   \n",
       "1            0              0                   1           0       0   \n",
       "2            0              0                   0           0       0   \n",
       "3            0              0                   0           0       0   \n",
       "4            0              0                   0           0       0   \n",
       "...        ...            ...                 ...         ...     ...   \n",
       "4995         0              0                   0           0       1   \n",
       "4996        85              0                   0           0       1   \n",
       "4997         0              0                   0           0       0   \n",
       "4998         0              0                   0           0       1   \n",
       "4999         0              0                   0           0       1   \n",
       "\n",
       "      CreditCard  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              1  \n",
       "...          ...  \n",
       "4995           0  \n",
       "4996           0  \n",
       "4997           0  \n",
       "4998           0  \n",
       "4999           1  \n",
       "\n",
       "[5000 rows x 14 columns]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_df = pd.read_csv(\"../data/raw/bank.csv\", sep=\",\")\n",
    "real_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resemblance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, ks_2samp\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_categorical_similarity(col_real, col_synthetic):\n",
    "    # Compute Theil's U for categorical features\n",
    "    p_real = pd.Series(col_real).value_counts(normalize=True)\n",
    "    p_synthetic = pd.Series(col_synthetic).value_counts(normalize=True)\n",
    "    u = (p_real * np.log(p_real / p_synthetic)).sum()\n",
    "    return 1 - u\n",
    "def column_similarity(real_data, synthetic_data):\n",
    "    similarities = []\n",
    "    for col_real, col_synthetic in zip(real_data, synthetic_data):\n",
    "        correlation, _ = pearsonr(col_real, col_synthetic)\n",
    "        similarity = correlation\n",
    "        similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "def correlation_similarity(real_data, synthetic_data):\n",
    "    real_corr = np.corrcoef(real_data, rowvar=False)\n",
    "    synthetic_corr = np.corrcoef(synthetic_data, rowvar=False)\n",
    "    correlation, _ = pearsonr(real_corr.flatten(), synthetic_corr.flatten())\n",
    "    return correlation\n",
    "def jensen_shannon_similarity(real_data, synthetic_data):\n",
    "    similarities = []\n",
    "    for col_real, col_synthetic in zip(real_data.T, synthetic_data.T):\n",
    "        # Compute probability distributions and Jensen-Shannon divergence\n",
    "        p_real = np.histogram(col_real, bins=10, density=True)[0]\n",
    "        p_synthetic = np.histogram(col_synthetic, bins=10, density=True)[0]\n",
    "        similarity = 1 - jensenshannon(p_real, p_synthetic)\n",
    "        similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "def kolmogorov_smirnov_similarity(real_data, synthetic_data):\n",
    "    similarities = []\n",
    "    for col_real, col_synthetic in zip(real_data.T, synthetic_data.T):\n",
    "        # Compute cumulative distributions and Kolmogorov-Smirnov distance\n",
    "        similarity, _ = ks_2samp(col_real, col_synthetic)\n",
    "        similarity = 1 - similarity\n",
    "        similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "def propensity_mean_absolute_similarity(real_data, synthetic_data):\n",
    "    # Train XGBoost classifier to discriminate between real and synthetic samples\n",
    "    X = np.vstack([real_data, synthetic_data])\n",
    "    y = np.concatenate([np.ones(len(real_data)), np.zeros(len(synthetic_data))])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    classifier = XGBClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # Compute mean absolute error of classifier probabilities\n",
    "    y_pred_proba = classifier.predict_proba(X_test)[:, 1]\n",
    "    error = mean_absolute_error(y_test, y_pred_proba)\n",
    "    return 1 - error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resemblance_measure(real_data, synthetic_data):\n",
    "    resemblance_score = (\n",
    "        column_similarity(real_data, synthetic_data) +\n",
    "        # correlation_similarity(real_data, synthetic_data) +\n",
    "        jensen_shannon_similarity(real_data, synthetic_data) +\n",
    "        kolmogorov_smirnov_similarity(real_data, synthetic_data) +\n",
    "        propensity_mean_absolute_similarity(real_data, synthetic_data)\n",
    "    ) / 4\n",
    "    print(\"Resemblance Score:\", resemblance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resemblance Score: 0.7286024662155156\n"
     ]
    }
   ],
   "source": [
    "resemblance_measure(real_df.to_numpy(), gen_df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8199714285714287"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3932, -0.8682, -1.1596,  ..., -0.8412, -0.5718, -1.4147],\n",
       "        [ 0.7493,  0.7483,  0.2192,  ..., -2.0034,  0.0314,  0.5073],\n",
       "        [ 1.0134,  0.0577,  0.1007,  ..., -1.1991, -0.9231,  1.1146],\n",
       "        ...,\n",
       "        [-0.0114,  0.6614,  1.5838,  ..., -0.1003,  0.3698,  0.6999],\n",
       "        [-0.1677,  0.8268,  1.7657,  ...,  0.9278,  1.1973,  1.3407],\n",
       "        [-0.6537,  1.0815, -0.8706,  ...,  0.0641, -1.4515, -0.3803]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_data = pd.read_csv(\"../data/processed/bank,.csv\", sep=\",\")\n",
    "\n",
    "\n",
    "torch.tensor(embedding_data.to_numpy(), dtype=torch.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 ('distributed-3-9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71c2bb8a9aafac3189ddd139a8a38ed74f79c7c3756567015645529460b394b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
